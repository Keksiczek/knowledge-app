# Knowledge App – Configuration
# Environment variables are expanded with ${VAR_NAME} syntax in any string field.

llm:
  # Which provider to use by default on startup
  default_provider: "ollama"

  # Shared generation parameters (apply to all providers unless overridden)
  generation:
    temperature: 0.2
    max_tokens: 4096
    top_p: 0.9

  # Provider-specific configuration
  providers:

    ollama:
      enabled: true
      base_url: "http://localhost:11434"
      default_model: "llama3.2:latest"
      timeout: 120

    lm_studio:
      enabled: false
      base_url: "http://localhost:1234/v1"
      api_key: ""                          # optional – LM Studio usually needs none
      default_model: "local-model"
      timeout: 120

    text_generation_webui:
      enabled: false
      base_url: "http://localhost:5000"
      default_model: "default"
      timeout: 120

    localai:
      enabled: false
      base_url: "http://localhost:8080/v1"
      api_key: ""
      default_model: "gpt-3.5-turbo"
      timeout: 120

    openai:
      enabled: false
      api_key: "${OPENAI_API_KEY}"         # loaded from environment
      default_model: "gpt-4o"
      organization: ""                     # optional OpenAI org ID
      timeout: 60

    anthropic:
      enabled: false
      api_key: "${ANTHROPIC_API_KEY}"
      default_model: "claude-sonnet-4-5-20250514"
      timeout: 60

database:
  engine: "sqlite"
  path: "./data/knowledge.db"

storage:
  upload_dir: "./uploads"
  max_file_size_mb: 50

rag:
  chunk_size: 512
  chunk_overlap: 64
  top_k: 5
  embedding_model: "all-MiniLM-L6-v2"

app:
  host: "0.0.0.0"
  port: 8000
  cors_origins:
    - "http://localhost:3000"
    - "http://localhost:8080"
    - "http://127.0.0.1:8080"
